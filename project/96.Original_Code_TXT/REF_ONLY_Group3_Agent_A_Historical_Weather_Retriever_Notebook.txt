import requests
import numpy as np
import pandas as pd
import torch
from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score
from datetime import datetime
import re
import os
import random

# Parameters
data_dir = '/home/ubuntu/efs-w210-capstone-ebs/00.GabbleGrid/02.Local_Data_Files'
save_dir = '/home/ubuntu/efs-w210-capstone-ebs/00.GabbleGrid/project/admin/01.Templates'
file_prefix = "06.20240714_062624_non_overlap_full_test"

# Define the number of records for each test run (input_length + gap + prediction_period)
num_records_per_test = lambda input_length, gap, prediction_period: input_length + gap + prediction_period

# Load the test data
X_test = np.load(f"{data_dir}/{file_prefix}_X_test.npy")
y_test = np.load(f"{data_dir}/{file_prefix}_y_test.npy")

# Load the original parquet file with sequence mapping
input_file = f"{data_dir}/03.20240715_143154_orig_input_w_seq_info_FINAL.parquet"
original_df = pd.read_parquet(input_file)

# Ensure Seq_Num is integer for proper merging
original_df['Seq_Num'] = original_df['Seq_Num'].astype(int)

# Function to prepare data for the model
def prepare_data_for_model(X_test, start_seq_num, num_records_per_test, num_tests, original_df, max_events):
    start_index_x_test = (start_seq_num - original_df[original_df['Train_Test'] == 'Test']['Seq_Num'].min()) // num_records_per_test
    end_index_x_test = min(start_index_x_test + num_tests, len(X_test))
    X_test_limited = X_test[start_index_x_test:end_index_x_test]
    X_test_limited = X_test_limited[:, :, 1:max_events + 16]
    X_test_tensor = torch.tensor(X_test_limited, dtype=torch.float32)
    return X_test_tensor, start_index_x_test, end_index_x_test

# Function to clean text
def clean_text(text):
    text = re.sub(r'<\*?>', '', text)
    text = text.replace('<', '').replace('>', '')
    return text

# Function to consolidate events and map to templates
def consolidate_events_to_text(df, start_col, end_col, col_name, master_tracking_df, eventid_to_template):
    consolidated = []
    for i, row in df.iterrows():
        seen_events = set()
        events = []
        for seq_num in range(row[start_col], row[end_col] + 1):
            if col_name in master_tracking_df.columns:
                event_list = master_tracking_df[master_tracking_df['Seq_Num'] == seq_num][col_name].astype(str).tolist()
                for event in event_list:
                    for e in event.split(', '):
                        if e not in seen_events:
                            seen_events.add(e)
                            if int(e) in eventid_to_template:
                                cleaned_text = clean_text(eventid_to_template[int(e)])
                                events.append(f'"{cleaned_text}"')
                            else:
                                events.append('"Unknown"')
        consolidated.append(', '.join(events))
    return consolidated

# Main function to run the experiment
def run_experiment(max_events, input_length, gap, prediction_period, start_time, num_tests):
    filtered_df = original_df[(original_df['Train_Test'] == 'Test') & (original_df['time_start'] == start_time)]
    if filtered_df.empty:
        start_date = pd.to_datetime(start_time).date()
        same_date_df = original_df[(original_df['Train_Test'] == 'Test') & (pd.to_datetime(original_df['time_start']).dt.date == start_date)]
        if not same_date_df.empty:
            available_times = same_date_df['time_start'].unique().tolist()
            # print(f"Error: start_time {start_time} not found in the dataset. Available times on {start_date} are: {available_times}")
        all_times_df = original_df[original_df['Train_Test'] == 'Test'].copy()
        all_times_df['time_start'] = pd.to_datetime(all_times_df['time_start'])
        nearest_time = all_times_df.iloc[(all_times_df['time_start'] - pd.to_datetime(start_time)).abs().argsort()[:1]]['time_start'].values[0]
        # print(f"Error: start_time {start_time} not found in the dataset. The nearest available time is: {nearest_time}")
        start_time = nearest_time  # Update the start_time to the nearest available time
        filtered_df = original_df[(original_df['Train_Test'] == 'Test') & (original_df['time_start'] == start_time)].copy()

    start_seq_num = int(filtered_df['Seq_Num'].values[0])
    max_end_seq_num = int(original_df[original_df['Train_Test'] == 'Test']['Seq_Num'].max())
    expected_end_seq_num = start_seq_num + num_tests * num_records_per_test(input_length, gap, prediction_period) - 1

    if expected_end_seq_num > max_end_seq_num:
        max_allowed_runs = (max_end_seq_num - start_seq_num + 1) // num_records_per_test(input_length, gap, prediction_period)
        # print(f"Number of test runs exceeds the maximum allowed ({max_allowed_runs}). Setting num_tests to {max_allowed_runs}.")
        num_tests = max_allowed_runs
        expected_end_seq_num = start_seq_num + num_tests * num_records_per_test(input_length, gap, prediction_period) - 1

    X_test_tensor, start_index_x_test, end_index_x_test = prepare_data_for_model(X_test, start_seq_num, num_records_per_test(input_length, gap, prediction_period), num_tests, original_df, max_events)

    # print(f"X_test shape after adjusting columns: {X_test_tensor.shape}")

    data = {
        'X_test': X_test_tensor.tolist(),
        'input_length': input_length,
        'gap': gap,
        'prediction_period': prediction_period,
        'max_events': max_events
    }

    response = requests.post('http://0.0.0.0:5000/predict', json=data)

    # print("Raw response text:", response.text)

    try:
        response_data = response.json()
    except ValueError as e:
        print("Failed to parse JSON response:", e)
        response_data = {}

    if 'predictions' in response_data:
        predictions = np.array(response_data['predictions']).flatten()
        model_name = response_data.get('model_name', 'unknown_model')

        num_predictions = len(predictions)
        num_tests = min(num_tests, num_predictions)  # Adjust num_tests to the number of predictions returned

        tracking_data = []

        for i in range(num_tests):
            total_seq_start = start_seq_num + i * num_records_per_test(input_length, gap, prediction_period)
            total_seq_end = total_seq_start + num_records_per_test(input_length, gap, prediction_period) - 1
            source_seq_start = total_seq_start
            source_seq_end = source_seq_start + input_length - 1
            gap_seq_start = source_seq_end + 1
            gap_seq_end = gap_seq_start + gap - 1
            prediction_seq_start = total_seq_end - prediction_period + 1
            prediction_seq_end = total_seq_end
            
            tracking_data.append([
                total_seq_start, total_seq_end, source_seq_start, source_seq_end,
                gap_seq_start, gap_seq_end, prediction_seq_start, prediction_seq_end,
                predictions[i], y_test[start_index_x_test + i],
                str(original_df[original_df['Seq_Num'] == source_seq_start]['time_start'].values[0])
            ])

        tracking_df = pd.DataFrame(tracking_data, columns=[
            "Total_Seq_Start", "Total_Seq_End", "Source_Seq_Start", "Source_Seq_End",
            "Gap_Seq_Start", "Gap_Seq_End", "Prediction_Seq_Start", "Prediction_Seq_End",
            "Predicted", "Actual", "time_start"
        ])

        conf_matrix = confusion_matrix(y_test[start_index_x_test:end_index_x_test], predictions, labels=[0, 1])
        precision = precision_score(y_test[start_index_x_test:end_index_x_test], predictions, zero_division=0)
        recall = recall_score(y_test[start_index_x_test:end_index_x_test], predictions, zero_division=0)
        accuracy = accuracy_score(y_test[start_index_x_test:end_index_x_test], predictions)
        f1 = f1_score(y_test[start_index_x_test:end_index_x_test], predictions, zero_division=0)

        if conf_matrix.size == 4:
            tn, fp, fn, tp = conf_matrix.ravel()
        else:
            tn = conf_matrix[0, 0] if conf_matrix.shape[0] > 0 else 0
            fp = conf_matrix[0, 1] if conf_matrix.shape[1] > 1 else 0
            fn = conf_matrix[1, 0] if conf_matrix.shape[0] > 1 else 0
            tp = conf_matrix[1, 1] if conf_matrix.shape[1] > 1 else 0

        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
        metrics_data = {
            'Experiment': [timestamp] * num_tests,
            'Sample': list(range(1, num_tests + 1)),
            'Max_Events': [max_events] * num_tests,
            'Input_Length': [input_length] * num_tests,
            'Gap': [gap] * num_tests,
            'Prediction_Period': [prediction_period] * num_tests,
            'Exp_Start_Time': [start_time] * num_tests,
            'Num_Tests': [num_tests] * num_tests,
            'Model_Name': [model_name] * num_tests,
            'Precision': [precision] * num_tests,
            'Recall': [recall] * num_tests,
            'Accuracy': [accuracy] * num_tests,
            'F1_Score': [f1] * num_tests,
            'TN': [tn] * num_tests,
            'FP': [fp] * num_tests,
            'FN': [fn] * num_tests,
            'TP': [tp] * num_tests
        }
        metrics_df = pd.DataFrame(metrics_data)

        combined_df = pd.concat([metrics_df, tracking_df], axis=1)

        master_tracking_file = f"{data_dir}/03B.20240716_072206_orig_parquet_mapper_agents.parquet"
        master_tracking_df = pd.read_parquet(master_tracking_file)

        merged_df = combined_df.merge(master_tracking_df, left_on='Source_Seq_Start', right_on='Seq_Num', how='left')

        merged_df.rename(columns={'time_start_y': 'Sample_Start_Time'}, inplace=True)

        columns_to_keep = [
            "Experiment", "Sample", "Max_Events", "Input_Length", "Gap", "Prediction_Period",
            "Exp_Start_Time", "Num_Tests", "Model_Name", "Precision", "Recall", "Accuracy", "F1_Score", "TN", "FP", "FN", "TP",
            "Total_Seq_Start", "Total_Seq_End", "Source_Seq_Start", "Source_Seq_End", "Gap_Seq_Start",
            "Gap_Seq_End", "Prediction_Seq_Start", "Prediction_Seq_End", "Predicted", "Actual", "Sample_Start_Time",
            "Class", "unique_events", "most_frequent_event", "transitions", "entropy", "hour_of_day", "day_of_week",
            "event_count", "top_event_frequency", "prev_event_count", "transition_rate", "high_transition_rate",
            "prev_entropy", "entropy_change", "rolling_event_count", "rolling_unique_event_count"
        ]

        missing_columns = [col for col in columns_to_keep if col not in merged_df.columns]
        # if missing_columns:
            # print(f"Warning: The following columns are missing from merged_df: {missing_columns}")

        columns_to_keep = [col if col != 'time_start' else 'Sample_Start_Time' for col in columns_to_keep]

        filtered_df = merged_df[columns_to_keep].copy()

        eventid_encoding_file = f"{data_dir}/08.20240716031626_event_ID_int_template_mapping.csv"
        eventid_encoding_df = pd.read_csv(eventid_encoding_file)

        eventid_to_template = dict(zip(eventid_encoding_df['EncodedValue'], eventid_encoding_df['EventTemplate']))

        filtered_df['runtime_most_frequent_consl_text'] = consolidate_events_to_text(filtered_df, 'Source_Seq_Start', 'Source_Seq_End', 'most_frequent_event', master_tracking_df, eventid_to_template)
        filtered_df['runtime_least_frequent_consl_text'] = consolidate_events_to_text(filtered_df, 'Source_Seq_Start', 'Source_Seq_End', 'most_frequent_event', master_tracking_df, eventid_to_template)

        final_file = f"{save_dir}/A-Template_Detail.parquet"

        # filtered_df['Experiment'] = filtered_df['Experiment'].astype(int)
        filtered_df['Experiment'] = filtered_df['Experiment'].astype(str)

        filtered_df['Exp_Start_Time'] = filtered_df['Exp_Start_Time'].astype(str)  # Convert Exp_Start_Time to string
        
        if os.path.exists(final_file):
            existing_df = pd.read_parquet(final_file)
            combined_final_df = pd.concat([existing_df, filtered_df])
            combined_final_df.to_parquet(final_file, index=False)
        else:
            filtered_df.to_parquet(final_file, index=False)
        
        # print(f"Final file with consolidated columns saved to: {final_file}")

        saved_results = pd.read_parquet(final_file)
        # print("********************** Displaying the last 5 rows from the saved parquet file (Tail)  ******************************************")
        # display(saved_results.tail(5))

    # else:
        # print("No predictions found in the response.")

# Define parameter ranges
max_events_list = [5, 10, 20, 30, 40]
input_length_list = [20, 30]
gap_list = [1, 2, 3, 4, 5]
prediction_period_list = [1]
start_times_list = pd.date_range(start='2005-11-08', end='2006-01-04').strftime('%Y-%m-%d %H:%M:%S').tolist()
num_tests_list = list(range(10, 131))

# Generate 5 random parameter combinations
random_combinations = random.sample([
    (max_events, input_length, gap, prediction_period, start_time, num_tests)
    for max_events in max_events_list
    for input_length in input_length_list
    for gap in gap_list
    for prediction_period in prediction_period_list
    for start_time in start_times_list
    for num_tests in num_tests_list
], 1)

# Run the experiments
for combination in random_combinations:
    max_events, input_length, gap, prediction_period, start_time, num_tests = combination
    print(f"Running experiment with parameters: max_events={max_events}, input_length={input_length}, gap={gap}, prediction_period={prediction_period}, start_time={start_time}, num_tests={num_tests}")
    run_experiment(max_events, input_length, gap, prediction_period, start_time, num_tests)